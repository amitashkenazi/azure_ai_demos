{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab is according to https://towardsdatascience.com/a-pythonistas-intro-to-semantic-kernel-af5a1a39564d#360e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4\n",
      "https://openai-sweden-aash.openai.azure.com/\n",
      "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\n",
      "e49d588f9d214cd3a6d56b413e96734e\n"
     ]
    }
   ],
   "source": [
    "import semantic_kernel as sk\n",
    "# loadenv\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "print(os.environ.get(\"OPENAI_DEPLOYMENT_NAME\"))\n",
    "print(os.environ.get(\"OPENAI_ENDPOINT\"))\n",
    "print(os.environ.get(\"OPENAI_API_KEY\"))\n",
    "print(os.environ.get(\"AZURE_OPENAI_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/aashkenazi/anaconda3/envs/ai_demos/lib/python3.11/site-packages (2.1.2)\n",
      "Requirement already satisfied: filelock in /Users/aashkenazi/anaconda3/envs/ai_demos/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/aashkenazi/anaconda3/envs/ai_demos/lib/python3.11/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Users/aashkenazi/anaconda3/envs/ai_demos/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/aashkenazi/anaconda3/envs/ai_demos/lib/python3.11/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/aashkenazi/anaconda3/envs/ai_demos/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/aashkenazi/anaconda3/envs/ai_demos/lib/python3.11/site-packages (from torch) (2023.12.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/aashkenazi/anaconda3/envs/ai_demos/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/aashkenazi/anaconda3/envs/ai_demos/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text completion services: []\n",
      "Chat completion services: []\n",
      "Text embedding generation services: []\n"
     ]
    }
   ],
   "source": [
    "kernel = sk.Kernel()\n",
    "def print_ai_services(kernel):\n",
    "    print(f\"Text completion services: {kernel.all_text_completion_services()}\")\n",
    "    print(f\"Chat completion services: {kernel.all_chat_services()}\")\n",
    "    print(\n",
    "        f\"Text embedding generation services: {kernel.all_text_embedding_generation_services()}\"\n",
    "    )\n",
    "print_ai_services(kernel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.ai.open_ai import (\n",
    "    AzureChatCompletion,\n",
    "    AzureTextCompletion,\n",
    "    OpenAITextCompletion,\n",
    "    OpenAIChatCompletion,\n",
    ")\n",
    "azure = True\n",
    "openai = False\n",
    "if azure:\n",
    "    kernel.add_text_completion_service(\n",
    "        service_id=\"azure_gpt35_text_completion\",\n",
    "        service=AzureTextCompletion(\n",
    "            deployment_name='gpt-35-turbo-instruct', \n",
    "            endpoint=os.environ.get(\"OPENAI_ENDPOINT\"), \n",
    "            api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "        ),\n",
    "    )\n",
    "    gpt35_chat_service = AzureChatCompletion(\n",
    "        deployment_name='gpt-35-turbo',\n",
    "        endpoint=os.environ.get(\"OPENAI_ENDPOINT\"),\n",
    "        api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    )\n",
    "    kernel.add_chat_service(\"azure_gpt35_chat_completion\", gpt35_chat_service)\n",
    "elif openai:\n",
    "    kernel.add_text_completion_service(\n",
    "        service_id=\"openai_gpt35_text_completion\",\n",
    "        service= OpenAITextCompletion(\n",
    "            ai_model_id=\"gpt-3.5-turbo-instruct\",\n",
    "            api_key=os.environ.get(\"OPENAI_API_KEY\")\n",
    "        ),\n",
    "    )\n",
    "    openai_gpt35_chat_service = OpenAIChatCompletion(\n",
    "        ai_model_id=\"gpt-3.5-turbo-instruct\",\n",
    "        api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    )\n",
    "    kernel.add_chat_service(\"openai_gpt35_chat_completion\", openai_gpt35_chat_service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text completion services: ['azure_gpt35_text_completion', 'azure_gpt35_chat_completion']\n",
      "Chat completion services: ['azure_gpt35_chat_completion']\n",
      "Text embedding generation services: []\n"
     ]
    }
   ],
   "source": [
    "# kernel.remove_text_completion_service(\"azure_gpt35_text_completion\")\n",
    "print_ai_services(kernel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "{{$input}} is the capital city of\n",
    "\"\"\"\n",
    "\n",
    "generate_capital_city_text = kernel.create_semantic_function(\n",
    "    prompt, max_tokens=100, temperature=0, top_p=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='f_c599a11c_db93_4df5_bd35_a4a78ea29eb9' skill_name='_GLOBAL_FUNCTIONS_' description='Generic function, unknown purpose' is_semantic=True parameters=[ParameterView(name='input', description='', default_value='', type_='string', required=False)] is_asynchronous=True\n",
      "CompleteRequestSettings(temperature=0, top_p=0, presence_penalty=0.0, frequency_penalty=0.0, max_tokens=100, stop_sequences=[], number_of_responses=1, logprobs=0, token_selection_biases={}, chat_system_prompt='Assistant is a large language model.')\n"
     ]
    }
   ],
   "source": [
    "print(generate_capital_city_text.describe())\n",
    "print(generate_capital_city_text.request_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France. It is located in the northern part of the country, on the banks of the Seine River. Paris is known for its iconic landmarks such as the Eiffel Tower, Notre-Dame Cathedral, and the Louvre Museum. It is also known for its fashion, cuisine, and art scene. Paris is a major cultural, economic, and political center, and is often referred to as the \"City of Light\" due to its role as a center of enlightenment during the Age of Enlightenment\n"
     ]
    }
   ],
   "source": [
    "response = generate_capital_city_text(\"Paris\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paris\n"
     ]
    }
   ],
   "source": [
    "generate_capital_city_text_error = kernel.create_semantic_function(prompt, max_tokens=100, temperature=-1, top_p=0)\n",
    "error_response = generate_capital_city_text_error(\"Paris\")\n",
    "print(error_response.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading gpt-2 from hf.\n",
    "# from semantic_kernel.connectors.ai.hugging_face import HuggingFaceTextCompletion\n",
    "\n",
    "# hf_model = HuggingFaceTextCompletion(\"gpt2\", task=\"text-generation\")\n",
    "# kernel.add_text_completion_service(\"hf_gpt2_text_completion\", hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_config_dict = {\n",
    "    \"schema\": 1,\n",
    "    # The type of prompt\n",
    "    \"type\": \"completion\",\n",
    "    # A description of what the semantic function does\n",
    "    \"description\": \"Provides information about a capital city, which is given as an input, using the GPT2 model\",\n",
    "    # Specifies which model service(s) to use\n",
    "    \"default_services\": [\"azure_gpt35_text_completion\"],\n",
    "    # The parameters that will be passed to the connector and model service\n",
    "    \"completion\": {\n",
    "        \"temperature\": 0.01,\n",
    "        \"top_p\": 1,\n",
    "        \"max_tokens\": 256,\n",
    "        \"number_of_responses\": 1,\n",
    "    },\n",
    "    # Defines the variables that are used inside of the prompt\n",
    "    \"input\": {\n",
    "        \"parameters\": [\n",
    "            {\n",
    "                \"name\": \"input\",\n",
    "                \"description\": \"The name of the capital city\",\n",
    "                \"defaultValue\": \"London\",\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import PromptTemplateConfig\n",
    "\n",
    "prompt_template_config = PromptTemplateConfig.from_dict(hf_config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import PromptTemplate\n",
    "\n",
    "prompt_template = sk.PromptTemplate(\n",
    "    template=\"{{$input}} is the capital city of\",\n",
    "    prompt_config=prompt_template_config,\n",
    "    template_engine=kernel.prompt_template_engine,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import SemanticFunctionConfig\n",
    "\n",
    "function_config = SemanticFunctionConfig(prompt_template_config, prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import PromptTemplateConfig, SemanticFunctionConfig, PromptTemplate\n",
    "\n",
    "\n",
    "def create_semantic_function_config(prompt_template, prompt_config_dict, kernel):\n",
    "    prompt_template_config = PromptTemplateConfig.from_dict(prompt_config_dict)\n",
    "    prompt_template = sk.PromptTemplate(\n",
    "        template=prompt_template,\n",
    "        prompt_config=prompt_template_config,\n",
    "        template_engine=kernel.prompt_template_engine,\n",
    "    )\n",
    "    return SemanticFunctionConfig(prompt_template_config, prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_complete = kernel.register_semantic_function(\n",
    "    skill_name=\"GPT2Complete\",\n",
    "    function_name=\"gpt2_complete\",\n",
    "    function_config=create_semantic_function_config(\n",
    "        \"{{$input}} is the capital city of\", hf_config_dict, kernel\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = gpt2_complete(\"Paris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SKContext(memory=NullMemory(), variables=ContextVariables(variables={'input': ' France and is located in the northern part of the country. It is situated on the banks of the Seine River and is known for its iconic landmarks such as the Eiffel Tower, Notre-Dame Cathedral, and the Louvre Museum. Paris is also known for its fashion, cuisine, and art, making it a popular tourist destination. The city has a rich history, dating back to the 3rd century BC when it was originally a Celtic settlement. It has since been ruled by the Romans, the Franks, and eventually became the capital of the Kingdom of France in the 10th century. Today, Paris is a major global city and is home to over 2 million people. It is also a center for business, education, and culture, making it a vibrant and diverse city.'}), skill_collection=ReadOnlySkillCollection(data={'_global_functions_': {'f_c599a11c_db93_4df5_bd35_a4a78ea29eb9': SKFunction(FUNCTION_PARAM_NAME_REGEX='^[0-9A-Za-z_]*$', FUNCTION_NAME_REGEX='^[0-9A-Za-z_]*$', SKILL_NAME_REGEX='^[0-9A-Za-z_]*$'), 'f_a7981637_6a2b_4dd0_bfd8_4f1aa03ab2ba': SKFunction(FUNCTION_PARAM_NAME_REGEX='^[0-9A-Za-z_]*$', FUNCTION_NAME_REGEX='^[0-9A-Za-z_]*$', SKILL_NAME_REGEX='^[0-9A-Za-z_]*$')}, 'gpt2complete': {'gpt2_complete': SKFunction(FUNCTION_PARAM_NAME_REGEX='^[0-9A-Za-z_]*$', FUNCTION_NAME_REGEX='^[0-9A-Za-z_]*$', SKILL_NAME_REGEX='^[0-9A-Za-z_]*$')}}))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall': SKFunction(FUNCTION_PARAM_NAME_REGEX='^[0-9A-Za-z_]*$', FUNCTION_NAME_REGEX='^[0-9A-Za-z_]*$', SKILL_NAME_REGEX='^[0-9A-Za-z_]*$'),\n",
       " 'save': SKFunction(FUNCTION_PARAM_NAME_REGEX='^[0-9A-Za-z_]*$', FUNCTION_NAME_REGEX='^[0-9A-Za-z_]*$', SKILL_NAME_REGEX='^[0-9A-Za-z_]*$')}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel.import_skill(sk.core_skills.TextMemorySkill())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_with_context_plugin = \"\"\"\n",
    " Use the following pieces of context to answer the users question.\n",
    " This is the only information that you should use to answer the question, do not reference information outside of this context.\n",
    " If the information required to answer the question is not provided in the context, just say that \"I don't know\", don't try to make up an answer.\n",
    " ----------------\n",
    " Context: {{recall $question}}\n",
    " ----------------\n",
    " User question: {{$question}}\n",
    " ----------------\n",
    " Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_semantic_function_chat_config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 35\u001b[0m\n\u001b[1;32m      1\u001b[0m chat_config_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mschema\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# The type of prompt\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem_prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a chatbot to provide information about different cities and countries. \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     30\u001b[0m }\n\u001b[1;32m     32\u001b[0m chatbot_with_context_plugin \u001b[38;5;241m=\u001b[39m kernel\u001b[38;5;241m.\u001b[39mregister_semantic_function(\n\u001b[1;32m     33\u001b[0m     skill_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatbotWithContextPlugin\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     34\u001b[0m     function_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchatbot_with_context_plugin\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m---> 35\u001b[0m     function_config\u001b[38;5;241m=\u001b[39m\u001b[43mcreate_semantic_function_chat_config\u001b[49m(\n\u001b[1;32m     36\u001b[0m         prompt_with_context_plugin, chat_config_dict, kernel\n\u001b[1;32m     37\u001b[0m     ),\n\u001b[1;32m     38\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_semantic_function_chat_config' is not defined"
     ]
    }
   ],
   "source": [
    "chat_config_dict = {\n",
    "    \"schema\": 1,\n",
    "    # The type of prompt\n",
    "    \"type\": \"completion\",\n",
    "    # A description of what the semantic function does\n",
    "    \"description\": \"A chatbot which provides information about cities and countries\",\n",
    "    # Specifies which model service(s) to use\n",
    "    \"default_services\": [\"azure_gpt35_chat_completion\"],\n",
    "    # The parameters that will be passed to the connector and model service\n",
    "    \"completion\": {\n",
    "        \"temperature\": 0.0,\n",
    "        \"top_p\": 1,\n",
    "        \"max_tokens\": 500,\n",
    "        \"number_of_responses\": 1,\n",
    "        \"presence_penalty\": 0,\n",
    "        \"frequency_penalty\": 0,\n",
    "    },\n",
    "    # Defines the variables that are used inside of the prompt\n",
    "    \"input\": {\n",
    "        \"parameters\": [\n",
    "            {\n",
    "                \"name\": \"question\",\n",
    "                \"description\": \"The question given by the user\",\n",
    "                \"defaultValue\": \"\",\n",
    "            },\n",
    "        ]\n",
    "    },\n",
    "    # Non-schema variable\n",
    "    \"system_prompt\": \"You are a chatbot to provide information about different cities and countries. \",\n",
    "}\n",
    "\n",
    "chatbot_with_context_plugin = kernel.register_semantic_function(\n",
    "    skill_name=\"ChatbotWithContextPlugin\",\n",
    "    function_name=\"chatbot_with_context_plugin\",\n",
    "    function_config=create_semantic_function_chat_config(\n",
    "        prompt_with_context_plugin, chat_config_dict, kernel\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_demos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
